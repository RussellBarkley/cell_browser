{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ce7206c-f11e-4c6b-b588-8d31e470e72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'filename'],\n",
      "    num_rows: 10000\n",
      "})\n",
      "{'image': Image(mode=None, decode=True), 'filename': Value('string')}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943dd17c894341b0a06ddd675bab94fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\Anaconda3_2024.10-1\\envs\\cell_browser\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Work\\.cache\\huggingface\\hub\\datasets--RussellBarkley--msa-em-figures. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/RussellBarkley/msa-em-figures/commit/654b7f771e0e4948390ad0bb16334e3480217339', commit_message='Upload dataset', commit_description='', oid='654b7f771e0e4948390ad0bb16334e3480217339', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/RussellBarkley/msa-em-figures', endpoint='https://huggingface.co', repo_type='dataset', repo_id='RussellBarkley/msa-em-figures'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload a local folder of .tif files to a Hugging Face *dataset* repo (no sharding)\n",
    "\n",
    "# If not already installed in this env:\n",
    "# !pip install -U datasets huggingface_hub pillow\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset, Image\n",
    "from datasets.utils.logging import disable_progress_bar, set_verbosity_error\n",
    "\n",
    "# ── Silence logs/progress ────────────────────────────────────────────────\n",
    "disable_progress_bar()\n",
    "set_verbosity_error()\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "# ── Auth (choose ONE of these) ───────────────────────────────────────────\n",
    "# Option A: If you've already run `huggingface-cli login` in this environment, skip this.\n",
    "# Option B: Use an access token (recommended for notebooks). Paste your write token:\n",
    "# from huggingface_hub import login\n",
    "# login(\"<YOUR_WRITE_TOKEN>\")  # e.g. 'hf_xxx...'  ← your access code with write perms\n",
    "\n",
    "# ── Local data & target repo ─────────────────────────────────────────────\n",
    "DATA_DIR = r\"C:\\Users\\Work\\Desktop\\NucleusNet-10K\"   # 10,000 .tif files in a flat folder\n",
    "REPO_ID  = \"RussellBarkley/msa-em-figures\"          # target HF *dataset* repo\n",
    "\n",
    "# ── Build the dataset from a folder of images ────────────────────────────\n",
    "# Note: For a flat folder (no class subfolders), \"imagefolder\" will still create a \"label\" column.\n",
    "# We'll drop it so the dataset has just {\"image\", \"filename\"}.\n",
    "ds = load_dataset(\n",
    "    \"imagefolder\",\n",
    "    data_dir=DATA_DIR,\n",
    "    split=\"train\",\n",
    "    keep_in_memory=False,\n",
    ")\n",
    "\n",
    "# Remove dummy label column if present\n",
    "if \"label\" in ds.column_names:\n",
    "    ds = ds.remove_columns(\"label\")\n",
    "\n",
    "# Attach the filename while avoiding image decoding during the map\n",
    "ds = ds.cast_column(\"image\", Image(decode=False))\n",
    "\n",
    "def add_filename(ex):\n",
    "    return {\"filename\": os.path.basename(ex[\"image\"][\"path\"])}\n",
    "\n",
    "ds = ds.map(add_filename, batched=False)\n",
    "\n",
    "# Re-enable decode for sanity checks / downstream usage\n",
    "ds = ds.cast_column(\"image\", Image())\n",
    "\n",
    "print(ds)\n",
    "print(ds.features)  # {'image': Image(...), 'filename': Value('string')}\n",
    "\n",
    "# ── Push to hub without sharding ─────────────────────────────────────────\n",
    "# Set max_shard_size to something larger than your dataset size so it stays as ONE .arrow file.\n",
    "# (If your 10K TIFFs total, say, < 8–10 GB, \"50GB\" is plenty.)\n",
    "ds.push_to_hub(\n",
    "    REPO_ID,\n",
    "    private=True,            # set False if you want it public\n",
    "    max_shard_size=\"50GB\",   # force a single shard for this small dataset\n",
    "    # revision=\"main\",       # optional: target branch\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
