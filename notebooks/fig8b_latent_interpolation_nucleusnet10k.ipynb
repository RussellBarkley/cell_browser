{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60c3d42f-05b8-4f79-b216-e860f9c108a3",
   "metadata": {},
   "source": [
    "# Decoded latent interpolations between pairs from NucleusNet-10K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8894e88-92a0-448f-983d-a3fd3a331123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab99936e7a00436fb98a82adb904bb5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='info', description='Resample pairs', style=ButtonStyle()), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| label: nucleusnet10k-interpolation\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import os, random, math, logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as W\n",
    "from IPython.display import display\n",
    "from tifffile import imread as tiff_imread\n",
    "from urllib.parse import urlparse\n",
    "import fsspec\n",
    "from pathlib import Path\n",
    "\n",
    "# Quiet HF logs\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"TQDM_DISABLE\"] = \"1\"\n",
    "for _name in (\"fsspec\", \"huggingface_hub\", \"urllib3\", \"datasets\"):\n",
    "    logging.getLogger(_name).setLevel(logging.ERROR)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, Conv2DTranspose, AveragePooling2D,\n",
    "    Flatten, Dense, Reshape, ReLU\n",
    ")\n",
    "\n",
    "# ── Config ──────────────────────────────────────────────────────────────\n",
    "REPO_ID    = \"RussellBarkley/msa-em-figures\"\n",
    "BRANCH     = \"main\"\n",
    "WEIGHT_DIRS = [\n",
    "    Path(\"..\") / \"data\" / \"nucleus-ae\",\n",
    "]\n",
    "ENC_NAME    = 'encoder_weights.h5'\n",
    "DEC_NAME    = 'decoder_weights.h5'\n",
    "LATENT_DIM  = 512\n",
    "\n",
    "N_PAIRS   = 50\n",
    "T_VALUES  = np.round(np.linspace(0.0, 1.0, 6), 2)\n",
    "\n",
    "# ── Build models to match your AE ───────────────────────────────────────\n",
    "def build_encoder(latent_dim=LATENT_DIM):\n",
    "    inp = Input((256,256,1), name='encoder_input')\n",
    "    x = inp\n",
    "    for filters in [16, 32, 64, 128]:\n",
    "        x = Conv2D(filters, 3, padding='same')(x); x = ReLU()(x)\n",
    "        x = Conv2D(filters, 3, padding='same')(x); x = ReLU()(x)\n",
    "        x = AveragePooling2D(pool_size=2)(x)\n",
    "    flat = Flatten()(x)\n",
    "    z = Dense(latent_dim, name='z')(flat)\n",
    "    return Model(inp, z, name='encoder')\n",
    "\n",
    "def build_decoder(latent_dim=LATENT_DIM):\n",
    "    z_in = Input((latent_dim,), name='z_sampling')\n",
    "    x = Dense(16 * 16 * 128)(z_in)\n",
    "    x = Reshape((16, 16, 128))(x)\n",
    "    for filters in [128, 64, 32, 16]:\n",
    "        x = Conv2DTranspose(filters, 3, strides=2, padding='same')(x); x = ReLU()(x)\n",
    "        x = Conv2D(filters, 3, padding='same')(x); x = ReLU()(x)\n",
    "    out = Conv2D(1, 3, padding='same', activation='sigmoid', name='decoder_output')(x)\n",
    "    return Model(z_in, out, name='decoder')\n",
    "\n",
    "# Tame GPU memory spikes\n",
    "try:\n",
    "    for g in tf.config.list_physical_devices(\"GPU\"):\n",
    "        tf.config.experimental.set_memory_growth(g, True)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "encoder = build_encoder()\n",
    "decoder = build_decoder()\n",
    "\n",
    "# Try to find and load weights (silent)\n",
    "enc_path = dec_path = None\n",
    "for d in WEIGHT_DIRS:\n",
    "    e = os.path.join(d, ENC_NAME)\n",
    "    c = os.path.join(d, DEC_NAME)\n",
    "    if os.path.isfile(e) and os.path.isfile(c):\n",
    "        enc_path, dec_path = e, c\n",
    "        break\n",
    "\n",
    "latent_ready = False\n",
    "if enc_path and dec_path:\n",
    "    try:\n",
    "        encoder.load_weights(enc_path)\n",
    "        decoder.load_weights(dec_path)\n",
    "        latent_ready = True\n",
    "    except Exception:\n",
    "        pass  # stay silent\n",
    "# else: stay silent\n",
    "\n",
    "# ── HF file/dataset discovery ───────────────────────────────────────────\n",
    "USE_SIMPLECACHE = True\n",
    "fs_hf = fsspec.filesystem(\"hf\")\n",
    "\n",
    "def _ensure_hf_uri(p: str) -> str:\n",
    "    return p if p.startswith(\"hf://\") else (\"hf://\" + p.lstrip(\"/\"))\n",
    "\n",
    "def _maybe_cache(uri: str) -> str:\n",
    "    return f\"simplecache::{uri}\" if USE_SIMPLECACHE else uri\n",
    "\n",
    "def _basename_from_uri(uri: str) -> str:\n",
    "    return os.path.basename(urlparse(uri).path)\n",
    "\n",
    "def _list_all_tiff_paths():\n",
    "    globs = [\n",
    "        f\"hf://datasets/{REPO_ID}@{BRANCH}/**/*.tif\",\n",
    "        f\"hf://datasets/{REPO_ID}@{BRANCH}/**/*.tiff\",\n",
    "    ]\n",
    "    paths = []\n",
    "    for pat in globs:\n",
    "        try:\n",
    "            for p in fs_hf.glob(pat):\n",
    "                paths.append(_ensure_hf_uri(p))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return sorted(set(paths))\n",
    "\n",
    "ALL_PATHS = _list_all_tiff_paths()\n",
    "MODE = \"files\" if len(ALL_PATHS) > 0 else \"dataset\"\n",
    "\n",
    "DS_OBJ = None\n",
    "DS_LEN = 0\n",
    "if MODE == \"dataset\":\n",
    "    from datasets import load_dataset\n",
    "    DS_OBJ = load_dataset(REPO_ID, split=\"train\", keep_in_memory=False)\n",
    "    DS_LEN = len(DS_OBJ)\n",
    "\n",
    "# ── Helpers ─────────────────────────────────────────────────────────────\n",
    "def normalize01(x):\n",
    "    x = x.astype(np.float32)\n",
    "    return x/255.0 if x.max() > 1.0 else x\n",
    "\n",
    "def load_img_file_hf(uri: str):\n",
    "    with fsspec.open(_maybe_cache(uri), \"rb\") as f:\n",
    "        img = tiff_imread(f)\n",
    "    if img.ndim == 3:\n",
    "        if img.shape[-1] == 1:    img = img[...,0]\n",
    "        elif img.shape[-1] == 3:  img = 0.2126*img[...,0] + 0.7152*img[...,1] + 0.0722*img[...,2]\n",
    "        else:                     img = img[...,0]\n",
    "    if img.shape != (256,256):\n",
    "        raise ValueError(f\"{_basename_from_uri(uri)} has shape {img.shape}, expected 256x256.\")\n",
    "    return normalize01(img)\n",
    "\n",
    "def load_img_dataset_idx(idx: int):\n",
    "    ex = DS_OBJ[int(idx)]\n",
    "    arr = np.asarray(ex[\"image\"])\n",
    "    if arr.ndim == 3:\n",
    "        if arr.shape[-1] == 1:    arr = arr[...,0]\n",
    "        elif arr.shape[-1] == 3:  arr = 0.2126*arr[...,0] + 0.7152*arr[...,1] + 0.0722*arr[...,2]\n",
    "        else:                     arr = arr[...,0]\n",
    "    if arr.shape != (256,256):\n",
    "        raise ValueError(f\"sample_{idx} has shape {arr.shape}, expected 256x256.\")\n",
    "    return normalize01(arr)\n",
    "\n",
    "def encode_img(img01):\n",
    "    return encoder.predict(img01[None, ..., None], batch_size=8, verbose=0)[0]\n",
    "\n",
    "def decode_many(z_batch):\n",
    "    rec = decoder.predict(z_batch, batch_size=min(len(z_batch), 16), verbose=0)[..., 0]\n",
    "    return np.clip(rec, 0.0, 1.0)\n",
    "\n",
    "# ── Pair construction from FULL dataset (no 1k pre-sample) ──────────────\n",
    "rng_py = random.Random()\n",
    "\n",
    "def make_pairs_from_full(n_pairs=N_PAIRS):\n",
    "    pairs = []\n",
    "    if MODE == \"files\":\n",
    "        N = len(ALL_PATHS)\n",
    "        if N < 2:\n",
    "            return []\n",
    "        m = min(2*n_pairs, N)\n",
    "        idxs = list(range(N))\n",
    "        rng_py.shuffle(idxs)\n",
    "        chosen = idxs[:m]\n",
    "        for i in range(0, m - (m % 2), 2):\n",
    "            pairs.append((ALL_PATHS[chosen[i]], ALL_PATHS[chosen[i+1]]))\n",
    "        while len(pairs) < n_pairs:\n",
    "            a = ALL_PATHS[rng_py.randrange(N)]\n",
    "            b = ALL_PATHS[rng_py.randrange(N)]\n",
    "            pairs.append((a, b))\n",
    "    else:\n",
    "        N = DS_LEN\n",
    "        if N < 2:\n",
    "            return []\n",
    "        m = min(2*n_pairs, N)\n",
    "        idxs = list(range(N))\n",
    "        rng_py.shuffle(idxs)\n",
    "        chosen = idxs[:m]\n",
    "        for i in range(0, m - (m % 2), 2):\n",
    "            pairs.append((chosen[i], chosen[i+1]))  # store indices\n",
    "        while len(pairs) < n_pairs:\n",
    "            a = rng_py.randrange(N)\n",
    "            b = rng_py.randrange(N)\n",
    "            pairs.append((a, b))\n",
    "    return pairs\n",
    "\n",
    "# ── Widgets ─────────────────────────────────────────────────────────────\n",
    "w_rescan = W.Button(description=\"Resample pairs\", button_style=\"info\")\n",
    "w_pair   = W.IntSlider(value=0, min=0, max=N_PAIRS-1, step=1, description=\"Pair #\", readout=True, continuous_update=False)\n",
    "w_prev   = W.Button(description=\"Prev\")\n",
    "w_next   = W.Button(description=\"Next\")\n",
    "w_status = W.HTML(\"\")\n",
    "\n",
    "# ── Figure (single small row, ~4x2 in; titles above each image) ─────────\n",
    "_was_interactive = plt.isinteractive()\n",
    "plt.ioff()\n",
    "\n",
    "K = len(T_VALUES)\n",
    "n_cols, n_rows = K, 1\n",
    "\n",
    "FIG_W_IN, FIG_H_IN, DPI = 4.4, 2.0, 150\n",
    "fig = plt.figure(figsize=(FIG_W_IN, FIG_H_IN), dpi=DPI, constrained_layout=False)\n",
    "gs  = fig.add_gridspec(n_rows, n_cols)\n",
    "\n",
    "axes, ims = [], []\n",
    "for k in range(K):\n",
    "    ax = fig.add_subplot(gs[0, k])\n",
    "    im = ax.imshow(np.zeros((256, 256)), cmap=\"gray\", vmin=0, vmax=1)\n",
    "    ax.set_xticks([]); ax.set_yticks([]); ax.set_frame_on(False)\n",
    "    ax.set_title(f\"t={T_VALUES[k]:.2f}\", fontsize=6, pad=2)  # ← title above the image\n",
    "    axes.append(ax); ims.append(im)\n",
    "\n",
    "# Tight spacing; no forced 100% width so it won't zoom/stretch\n",
    "fig.subplots_adjust(left=0.01, right=0.99, bottom=0.02, top=0.88, wspace=0.02)\n",
    "fig.canvas.header_visible  = False\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.layout.width    = \"auto\"\n",
    "fig.canvas.layout.height   = \"auto\"\n",
    "\n",
    "if _was_interactive:\n",
    "    plt.ion()\n",
    "\n",
    "\n",
    "# ── State & cache ───────────────────────────────────────────────────────\n",
    "pairs = []   # files mode: list[(uriA, uriB)], dataset mode: list[(idxA, idxB)]\n",
    "pair_cache = {}  # idx -> dict('imgs', 'A','B','A_z','B_z')\n",
    "\n",
    "def set_status(msg, ok=True):\n",
    "    # keep a minimal status line; still helpful for errors\n",
    "    color = \"#1b5e20\" if ok else \"#b71c1c\"\n",
    "    w_status.value = f\"<span style='color:{color}'>{msg}</span>\"\n",
    "\n",
    "def _handle_to_name(h):\n",
    "    if MODE == \"files\":\n",
    "        return _basename_from_uri(h)\n",
    "    else:\n",
    "        return f\"sample_{int(h):06d}.tif\"\n",
    "\n",
    "def _load_handle(h):\n",
    "    if MODE == \"files\":\n",
    "        return load_img_file_hf(h)\n",
    "    else:\n",
    "        return load_img_dataset_idx(int(h))\n",
    "\n",
    "def show_frames(framesK, pair_idx):\n",
    "    for k, im in enumerate(ims):\n",
    "        im.set_data(framesK[k])\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "def compute_pair(idx):\n",
    "    if idx in pair_cache:\n",
    "        return pair_cache[idx][\"imgs\"]\n",
    "    a_h, b_h = pairs[idx]\n",
    "    A = _load_handle(a_h)\n",
    "    B = _load_handle(b_h)\n",
    "    A_z = encode_img(A)\n",
    "    B_z = encode_img(B)\n",
    "    Z = np.stack([(1.0 - t) * A_z + t * B_z for t in T_VALUES], axis=0)  # (K, latent_dim)\n",
    "    frames = decode_many(Z)                                              # (K, 256, 256)\n",
    "    pair_cache[idx] = {\"imgs\": frames, \"A\": a_h, \"B\": b_h, \"A_z\": A_z, \"B_z\": B_z}\n",
    "    return frames\n",
    "\n",
    "def on_rescan_clicked(_):\n",
    "    if not latent_ready:\n",
    "        set_status(\"Weights not loaded; cannot interpolate in latent space.\", ok=False)\n",
    "        return\n",
    "    if MODE == \"files\" and len(ALL_PATHS) < 2:\n",
    "        set_status(\"No TIFFs found in repo.\", ok=False)\n",
    "        return\n",
    "    if MODE == \"dataset\" and DS_LEN < 2:\n",
    "        set_status(\"Dataset is empty.\", ok=False)\n",
    "        return\n",
    "\n",
    "    global pairs, pair_cache\n",
    "    pairs = make_pairs_from_full(N_PAIRS)\n",
    "    pair_cache = {}\n",
    "    if not pairs:\n",
    "        set_status(\"Could not build pairs from the repository.\", ok=False)\n",
    "        return\n",
    "\n",
    "    w_pair.max = len(pairs)-1\n",
    "    w_pair.value = 0\n",
    "    # no verbose banner; just build silently and show first pair\n",
    "    try:\n",
    "        frames = compute_pair(0)\n",
    "        show_frames(frames, 0)\n",
    "    except Exception as ex:\n",
    "        set_status(f\"Failed pair 1: {ex}\", ok=False)\n",
    "\n",
    "def on_pair_change(change):\n",
    "    idx = int(change['new'])\n",
    "    if not pairs:\n",
    "        return\n",
    "    try:\n",
    "        frames = compute_pair(idx)\n",
    "        show_frames(frames, idx)\n",
    "    except Exception as ex:\n",
    "        set_status(f\"Failed pair {idx+1}: {ex}\", ok=False)\n",
    "\n",
    "def on_prev(_):\n",
    "    if pairs:\n",
    "        w_pair.value = max(0, w_pair.value - 1)\n",
    "\n",
    "def on_next(_):\n",
    "    if pairs:\n",
    "        w_pair.value = min(w_pair.max, w_pair.value + 1)\n",
    "\n",
    "w_rescan.on_click(on_rescan_clicked)\n",
    "w_pair.observe(on_pair_change, names='value')\n",
    "w_prev.on_click(on_prev)\n",
    "w_next.on_click(on_next)\n",
    "\n",
    "# ── Display ──────────\n",
    "container = W.VBox([\n",
    "    W.HBox([w_rescan, w_prev, w_next, w_pair]),\n",
    "    fig.canvas\n",
    "], layout=W.Layout(width=\"100%\"))\n",
    "display(container)\n",
    "\n",
    "# Kick off an initial build\n",
    "on_rescan_clicked(None)\n",
    "\n",
    "None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
