---
title: Chapter 1
---

# Introduction

Representative images are visual communication tools used by microscopists to present their research to other scientists. The earliest representative microscopy images were hand drawings in [Micrographia](<wiki:Micrographia>) in 1665 by Robert Hooke. Nowdays, roughly three-quarters of publications in biomedical journals report at least one microscopy image [@doi:10.7554/eLife.55133]. In scientific journals, microscopists must choose a representative image to report in a static figure, but image selection is vulnerable to bias and deception [@doi:10.1242/jcs.261567]. Blinding and automation are strategies that can reduce subjective biases in microscopy experimentation [@doi:10.1083/jcb.201812109] but while automated imaging is trivial and accessible with modern microscopes [@doi:10.1101/861856], the process of representative image selection remains a subjective, non-repeatable step in the scientific process. To address this, <https://doi.org/10.1016/s0006-3495(99)77379-0> developed automated methods for objective representative image selection from microscopy datasets. The authors implemented a web server that chose typical images from uploaded data, but it is now unsupported and there is no modern equivalent. It is important to study methods of objective representative image selection because these tools promote research integrity.

The task of objective representative microscopy image selection is a novel use case for artificial intelligence. It was first demonstrated in a study that used principal component analysis (PCA) and K-means clustering to select representative images from medical ultrasound video series [@doi:10.3389/fonc.2021.673775]. Another study tested a method for objective representative image selection from real-world datasets [@doi:10.1109/BIP60195.2023.10379342], though it did not involve neural networks. Their proposed method generated average images using measures of central tendency per pixel, then practical images were found in vector space using singular value decomposition (SVD). We reproduced these results and adapted their approach using the latent space of a convolutional [autoencoder](<wiki:Autoencoder>) model. Autoencoders are unsupervised deep learning models that compress and reconstruct images through a vector bottleneck referred to as _latent space_. The structure of latent space is a black box, though it can be shaped to be more useful with the art of representation learning [@doi:10.1109/TPAMI.2013.50]. For example, it was shown that the latent space of autoencoders trained on microscopy data was sensitive to cell orientation, so multi-encoder [@doi:10.1038/s42003-022-03218-x] and orientation-invariant [@doi:10.1038/s41467-024-45362-4] models were engineered to disentangle cell orientation in latent space. Autoencoders are commonly used for anomaly detection, which is based on the assumption that the autoencoder learns an optimal latent space to describe the normal data, so that when images are reconstructed, anomalous data will have a higher reconstruction error than normal data [@doi:10.1109/WTS.2018.8363930]. Though this assumption is flawed [@doi:10.48550/arXiv.2501.13864] and autoencoders can be unreliable anomaly detectors [@doi:10.1109/ICUFN57995.2023.10199315], it would suggest that autoencoders can determine normal data in a dataset to select an image.

There is no standard definition of a _representative image_ in the literature. Markey et al. defined it as the image that is most similar to all other images in the dataset. Soto-Quiros et al. referred to it as an image with the overall content and characteristics of the dataset. In either case, the assumption is that the representative image is not an outlier, nor anomalous. <https://doi.org/10.1016/s0006-3495(99)77379-0> established an important criterion for evaluating methods of representative image selection; ideal methods will always pick a member of the majority class as the most typical image. This criterion was established in experiments using contaminated datasets where normal data was the majority class and anomalies were the minority class, but this criterion can also extend to datasets with discrete phenotypes like the [cell cycle](<wiki:Cell cycle>). For example, <https://doi.org/10.1016/0014-4827(79)90553-6> found that the majority class of asynchronous populations of CV-1 cells was [interphase](#interphase), therefore an objective method to determine the typical image of a [cell nucleus](<wiki:Cell_nucleus>) should always pick a cell in interphase.

To automate the process of sample collection and image selection from traditional fluorescence confocal microscopy experiments, we generated a dataset of one million images of fixed DAPI-stained cell nuclei, sampled from one-hundred glass coverslips on an Olympus Fluoview FV3000 confocal microscope equipped with a motorized stage ([Figure 1a](#fig1)). We then trained a convolutional autoencoder model to embed and reconstruct these images ([Figure 1b](#fig1)) and we analyzed the compressed latent vectors to define representative microscopy images ([Figure 1c](#fig1)) near theoretical measures of central tendency in latent space, as a method of objective representative microscopy image selection.

```{figure} ./figures/fig1.png
:label: fig1
:align: center
:width: 100%
:enumerator: 1

An overview of data collection and representative image selection in our fluorescence confocal microscopy experiment. A) Automated grid collection imaging with a motorized stage on a confocal microscope covered large areas at high-resolution. B) Train an autoencoder to embed and reconstruct the collection of single-cell images of nuclei. C) Calculate average latent vectors to define representative images in latent space.
```

We sought to generate a large dataset because the performance of neural networks tend to scale with dataset size [@doi:10.48550/arXiv.1712.00409]. Further, a large dataset presents a conceptual challenge to the task of representative image selection, because it is unreasonable for a human to evaluate 1,000,000 images and only choose one to summarize the dataset. To address these limitations, we used interactive visualization strategies to present large panoramas and single-cell fluorescence microscopy images in a dynamic format. Interactive figures allow for comprehensive evaluation and it simulates the process that microscopists undergo to select a representative image. Consider that the criteria used to make subjective determinations about "representativeness" are unknown as discussed by <https://doi.org/10.1016/s0006-3495(99)77379-0>. We implement an autoencoder-based method of automatic image selection to report average images of cell nuclei from a single-cell microscopy dataset. Similarly, with insufficient representation learning, the criteria used to make objective determinations with an autoencoder model are also unknown. Prototypical images were selected based on distance metrics that defined each image with respect to the centroid of latent space in the bottleneck of an autoencoder model. The intuition behind this approach is consistent with previous reports on representative image selection and we found that it reliably identified normal data from our collection.

---

# Contributions

### 1. A confocal microscopy image dataset of over 1,000,000 masked cell nuclei.
Large regions of coverslips were sampled with automated imaging methods on a confocal microscope, yielding over 250,000 high-magnification fields that were stitched into 1,600 panoramas to mask and crop 1,061,277 ROIs. See [data availability](#data-availability) for repositories and archives.

### 2. A novel use case for autoencoders: representative image selection.
We show that autoencoders can select representative images from datasets. To our knowledge, this is among the first described methods of representative image selection to use a neural network [@doi:10.3389/fonc.2021.673775], especially an unsupervised deep learning model.