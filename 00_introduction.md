---
Chapter 1
---

# Introduction

Representative images are visual communication tools used by microscopists to present their research to other scientists. The earliest representative microscopy images were hand drawings in [Micrographia](<wiki:Micrographia>) in 1665 by Robert Hooke. Nowdays, roughly three-quarters of publications in biomedical journals report at least one microscopy image [@doi:10.7554/eLife.55133]. In traditional journals, microscopists must choose a representative image to report in a static figure, but image selection is vulnerable to bias and deception [@doi:10.1242/jcs.261567]. Blinding and automation are strategies that can reduce subjective biases in microscopy experimentation [@doi:10.1083/jcb.201812109]. While automated imaging is trivial and accessible with modern microscopes [@doi:10.1101/861856], the process of representative image selection remains a subjective, non-repeatable step in the scientific process. To address this, Markey et al. developed automated methods for objective representative image selection from microscopy datasets <https://doi.org/10.1016/s0006-3495(99)77379-0>. The authors implemented a web server that chose typical images from uploaded data, but it is now unsupported and there is no modern equivalent. It is important to research methods for objective representative image selection because these tools promote ethical research. Interactive figures are a dynamic solution for comprehensive microscopy data presentation [@doi:10.1242/jcs.262198], but scientific communication largely occurs through static figures.

The task of objective representative microscopy image selection is a novel use case for artificial intelligence. It was demonstrated in a study that used principal component analysis (PCA) and K-means clustering to select representative images from medical ultrasound video series [@doi:10.3389/fonc.2021.673775]. Another study tested a method for objective representative image selection from real-world datasets [@doi:10.1109/BIP60195.2023.10379342], though it did not involve neural networks. The proposed method generated average images using measures of central tendency per pixel, then practical images were found in vector space using singular value decomposition (SVD). We reproduced the results of this study and introduced a similar approach using the latent space of a convolutional [autoencoder](<wiki:Autoencoder>) model. Autoencoders are unsupervised deep learning models that compress and reconstruct images through a vector bottleneck referred to as _latent space_. The structure of latent space is a [black box](<wiki:Black box>) though it can be shaped to be more useful with the art of representation learning [@doi:10.1109/TPAMI.2013.50]. For example, it was shown that the latent space of autoencoders trained on microscopy data was sensitive to cell orientation, so multi-encoder [@doi:10.1038/s42003-022-03218-x] and orientation-invariant [@doi:10.1038/s41467-024-45362-4] models were engineered to disentangle cell orientation in latent space. Autoencoder models are commonly used for anomaly detection. This method is based on the assumption that the autoencoder learns an optimal latent space to describe the normal data, so that when images are reconstructed, anomalous data will have a higher reconstruction error than normal data [@doi:10.1109/WTS.2018.8363930]. Though this assumption is flawed [@doi:10.48550/arXiv.2501.13864] and autoencoders are unreliable anomaly detectors [@doi:10.1109/ICUFN57995.2023.10199315], it would suggest that autoencoders are a suitable model to define normal data for objective representative image selection.

There is no standard definition of a _representative image_ in the literature. Markey et al. defined it as the image that is most similar to all other images in the dataset. Soto-Quiros et al. referred to it as an image with the overall content and characteristics of the dataset. In either case, the representative image is not an outlier, nor anomalous. An important criterion for evaluating methods of representative image selection is that ideal methods will always pick a member of the majority class as the most typical image <https://doi.org/10.1016/s0006-3495(99)77379-0>. This criterion was established in experiments using contaminated datasets where normal data was the majority class and anomalies were the minority class, but this criterion can also extend to datasets with discrete phenotypes like the [cell cycle](<wiki:Cell cycle>). For example, we know that the majority class of an asynchronous population of cultured CV-1 cells is interphase <https://doi.org/10.1016/0014-4827(79)90553-6>, therefore an objective method to determine a typical image of a nucleus will always pick one that is in interphase.

To automate the process of sample collection and image selection in a traditional fluorescence microscopy experiment, we generated a dataset of one million images of the [cell nucleus](<wiki:Cell_nucleus>), sampled from one-hundred glass coverslips on a confocal microscope with a motorized stage (Figure 1A). We then trained a convolutional autoencoder model to reconstruct these images (Figure 1B) and analyzed the compressed latent vectors to define representative microscopy images (Figure 1C) near theoretical measures of central tendency in latent space, as a method of objective representative microscopy image selection.

```{figure} ./figures/Figure_1_workflow.png
:name: fig1
:align: center
:width: 100%

The method of automated data collection and representative image selection used in our fluorescence confocal microscopy experiments imaging the cell nucleus. A) 
```

We created a large dataset because the performance of neural networks tend to scale with model and dataset size [@doi:10.48550/arXiv.1712.00409]. Further, a large dataset presents a conceptual challenge to the task of representative image selection, because it is unreasonable for a human to evaluate 1,000,000 images and only choose one to summarize the dataset. To address these limitations, we used interactive visualization strategies to present large panoramas and single-cell fluorescence microscopy images in a dynamic format. Interactive figures enable a comprehensive evaluation and it simulates the process that microscopists undergo to select a representative image. Consider that the criteria used to make subjective determinations about "representativeness" are unknown <https://doi.org/10.1016/s0006-3495(99)77379-0>. We implement an autoencoder-based method of automatic image selection to report average images from the single-cell microscopy dataset. Similarly, with insufficient representation learning, the criteria used to make objective determinations with an autoencoder model are also unknown.

---

# Contributions

### 1. A single-cell microscopy dataset of 1,000,000 masked cell nuclei
We imaged over 250,000 high-magnification fields and stitched them into 1,600 stitched images. We masked the nuclei in the stitched images and used these masks to create the single-cell dataset. The data was deposited at ________ to facilitate the development of neural networks for microscopy use cases.

### 2. A method for ojective representative image selection using autoencoders
Autoencoder-based representative image selection is a non-linear dimensionality reduction technique to select normal images from a dataset. This is based on the same fundamental assumptions that autoencoder models reconstruct normal data better than anomalous data [@doi:10.1109/WTS.2018.8363930]. To our knowledge, this is among the first described methods of representative image selection that used a neural network [@doi:10.3389/fonc.2021.673775].